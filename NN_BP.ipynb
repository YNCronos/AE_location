{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmod(z):\n",
    "    h = 1./(1+np.exp(-z))\n",
    "    return h\n",
    "    \n",
    "def de_sigmoid(z,h):\n",
    "    return h*(1-h)\n",
    "    \n",
    "    \n",
    "def relu(z):\n",
    "    h = np.maximum(z, 0)\n",
    "    return h\n",
    "    \n",
    "def de_relu(z,h):\n",
    "    z[z <= 0] = 0\n",
    "    z[z > 0] = 1.0\n",
    "    return z\n",
    "    \n",
    "    \n",
    "    \n",
    "def no_active(z):\n",
    "    h = z\n",
    "    return h\n",
    "\n",
    "def de_no_active(z,h):\n",
    "    return np.ones(h.shape)\n",
    "    \n",
    "# o Nxc\n",
    "# lab Nxc    \n",
    "def loss_L2(o,lab):\n",
    "    diff = lab-o\n",
    "    sqrDiff = diff ** 2\n",
    "    return 0.5*np.sum(sqrDiff)\n",
    "    \n",
    "def de_loss_L2(o,lab):\n",
    "    return o-lab\n",
    "\n",
    "\n",
    "def loss_CE(o,lab):    \n",
    "    p = np.exp(o)/np.sum(np.exp(o),axis=1,keepdims=True)\n",
    "    loss_ce = np.sum(-lab*np.log(p))\n",
    "    return loss_ce\n",
    "\n",
    "def de_loss_CE(o,lab):\n",
    "    p = np.exp(o)/np.sum(np.exp(o),axis=1,keepdims=True)\n",
    "    return p-lab\n",
    "\n",
    "# dim_in:输入特征的维度\n",
    "# list_num_hidden： 每层输出节点的数目\n",
    "# list_act_funs： 每层的激活函数\n",
    "# list_de_act_funs: 反向传播时的函数\n",
    "\n",
    "def bulid_net(dim_in,list_num_hidden,\n",
    "              list_act_funs,list_de_act_funs):\n",
    "    layers=[]          \n",
    "    \n",
    "    # 逐层的进行网络构建\n",
    "    for i in range(len(list_num_hidden)):\n",
    "        layer = {}\n",
    "        \n",
    "        # 定义每一层的权重\n",
    "        if i ==0:\n",
    "            # layer[\"w\"]= 0.2*np.random.randn(dim_in,list_num_hidden[i])-0.1 # 用sigmoid激活函数\n",
    "            layer[\"w\"]= 0.01*np.random.randn(dim_in,list_num_hidden[i])  # 用relu 激活函数\n",
    "        else:\n",
    "            # layer[\"w\"]= 0.2*np.random.randn(list_num_hidden[i-1],list_num_hidden[i])-0.1 # 用sigmoid激活函数\n",
    "            layer[\"w\"]= 0.01*np.random.randn(list_num_hidden[i-1],list_num_hidden[i]) # 用relu 激活函数\n",
    "        \n",
    "        # 定义每一层的偏置\n",
    "        layer[\"b\"] = 0.1*np.ones([1,list_num_hidden[i]])\n",
    "        layer[\"act_fun\"]= list_act_funs[i]\n",
    "        layer[\"de_act_fun\"]= list_de_act_funs[i]\n",
    "        layers.append(layer)\n",
    "        \n",
    "    return layers\n",
    "    \n",
    "    \n",
    "# 返回每一层的输入\n",
    "# 与最后一层的输出    \n",
    "def fead_forward(datas,layers):\n",
    "    input_layers = []\n",
    "    input_acfun = []\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        if i ==0:\n",
    "            inputs = datas\n",
    "            z = np.dot(inputs,layer[\"w\"]) + layer[\"b\"]\n",
    "            h = layer['act_fun'](z)\n",
    "            input_layers.append(inputs)\n",
    "            input_acfun.append(z)\n",
    "        else:\n",
    "            inputs = h\n",
    "            z = np.dot(inputs,layer[\"w\"])+ layer[\"b\"]\n",
    "            h = layer['act_fun'](z)\n",
    "            input_layers.append(inputs)\n",
    "            input_acfun.append(z)\n",
    "    return input_layers,input_acfun,h\n",
    "\n",
    "\n",
    "# 进行参数更新更新    \n",
    "def updata_wb(datas,labs,layers, loss_fun,de_loss_fun,alpha=0.01):\n",
    "    N,D = np.shape(datas)\n",
    "    # 进行前馈操作\n",
    "    inputs,input_acfun,output = fead_forward(datas,layers)\n",
    "    # 计算 loss\n",
    "    loss = loss_fun(output,labs)\n",
    "    #从后向前计算\n",
    "    deltas0 = de_loss_fun(output,labs)\n",
    "    # 从后向前计算误差\n",
    "    deltas =[]\n",
    "    for i in range(len(layers)):\n",
    "        index = -i-1\n",
    "        if i ==0:\n",
    "            h = output\n",
    "            z = input_acfun[index]\n",
    "            delta = deltas0*layers[index][\"de_act_fun\"](z,h)\n",
    "        else:\n",
    "            h = inputs[index+1]\n",
    "            z = input_acfun[index]\n",
    "            # print(layers[index][\"de_act_fun\"](z,h)[1])\n",
    "            delta = np.dot(delta,layers[index+1][\"w\"].T)*layers[index][\"de_act_fun\"](z,h)\n",
    "        \n",
    "        deltas.insert(0,delta)\n",
    "    \n",
    "    # 利用误差 对每一层的权重进行修成\n",
    "    for i in range(len(layers)):\n",
    "        # 计算 dw 与 db\n",
    "        dw = np.dot(inputs[i].T,deltas[i])\n",
    "        db = np.sum(deltas[i],axis=0,keepdims=True)\n",
    "        # 梯度下降\n",
    "        layers[i][\"w\"] = layers[i][\"w\"] - alpha*dw\n",
    "        layers[i][\"b\"] = layers[i][\"b\"] - alpha*db\n",
    "        \n",
    "    return layers,loss\n",
    "    \n",
    "    \n",
    "def test_accuracy(datas,labs_true,layers):\n",
    "    _,_,output = fead_forward(datas,layers)\n",
    "    lab_det = np.argmax(output,axis=1)\n",
    "    labs_true = np.argmax(labs_true,axis=1) \n",
    "    N_error = np.where(np.abs(labs_true-lab_det)>0)[0].shape[0]\n",
    "   \n",
    "    error_rate = N_error/np.shape(datas)[0]\n",
    "    return error_rate\n",
    "\n",
    "    \n",
    "def load_dataset_iris(file_data,N_train):\n",
    "    # 数据读取\n",
    "    datas = np.loadtxt(file_data,dtype = np.float, delimiter = ',',usecols=(0,1,2,3))\n",
    "    labs = np.loadtxt(file_data,dtype = str, delimiter = ',',usecols=(4))\n",
    "    N,D = np.shape(datas)\n",
    "    N_test = N-N_train\n",
    "    unqiue_labs = np.unique(labs).tolist()\n",
    "    \n",
    "    dic_str2index={}\n",
    "    dic_index2str={}\n",
    "    for i in range(len(unqiue_labs)):\n",
    "        lab_str = unqiue_labs[i]\n",
    "        dic_str2index[lab_str] =i\n",
    "        dic_index2str[i]=lab_str\n",
    "    \n",
    "    labs_onehot = np.zeros([N,len(unqiue_labs)])\n",
    "    for i in range(N):\n",
    "        labs_onehot[i,dic_str2index[labs[i]]]=1\n",
    "    \n",
    "    perm = np.random.permutation(N)\n",
    "    index_train = perm[:N_train]\n",
    "    index_test = perm[N_train:]\n",
    "\n",
    "    data_train = datas[index_train,:]\n",
    "    lab_train_onehot = labs_onehot[index_train,:]\n",
    "\n",
    "    data_test = datas[index_test,:]\n",
    "    lab_test_onehot = labs_onehot[index_test]\n",
    "\n",
    "    return data_train,lab_train_onehot,data_test,lab_test_onehot,dic_index2str\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
